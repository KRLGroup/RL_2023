{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VjX_2mvrN7c1",
        "outputId": "739f2177-ada7-4f2b-8166-0151790723ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_nqTKTwODqj",
        "outputId": "b7d99f31-d263-4fca-f4be-5757ca29b61e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: swig in c:\\users\\michele\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.1.1.post1)\n",
            "Requirement already satisfied: gymnasium in c:\\users\\michele\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\michele\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium) (1.24.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\michele\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\michele\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium) (4.8.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\michele\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: gymnasium[box2d] in c:\\users\\michele\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\michele\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium[box2d]) (1.24.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\michele\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium[box2d]) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\michele\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium[box2d]) (4.8.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\michele\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in c:\\users\\michele\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium[box2d]) (2.3.5)\n",
            "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\michele\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium[box2d]) (2.5.1)\n",
            "Requirement already satisfied: swig==4.* in c:\\users\\michele\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gymnasium[box2d]) (4.1.1.post1)\n"
          ]
        }
      ],
      "source": [
        "!pip install swig\n",
        "!pip install gymnasium\n",
        "!pip install gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Aq405erfpGKv"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import pickle\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raB0pq_vuaak",
        "outputId": "58b2e7f3-6224-40ee-ced3-ef6bd1a42f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "x5Y4Y3eXugTc"
      },
      "outputs": [],
      "source": [
        "env_id = \"CarRacing-v2\"\n",
        "\n",
        "# Create the env\n",
        "env = gym.make(env_id, continuous=False, domain_randomize=False)\n",
        "\n",
        "# Create the evaluation env\n",
        "eval_env = gym.make(env_id, continuous=False, domain_randomize=False, render_mode=\"rgb_array\")\n",
        "\n",
        "# Get the state space and action space\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "n_frames = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NpSZGAuKulI6"
      },
      "outputs": [],
      "source": [
        "class Policy(nn.Module):\n",
        "    def __init__(self, n_frames, n_actions, hidden_size, img_size=(64,64), device=torch.device('cpu')):\n",
        "        super(Policy, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_frames = n_frames\n",
        "        self.conv1 = nn.Conv2d(n_frames, hidden_size, 7)\n",
        "        self.conv2 = nn.Conv2d(hidden_size, hidden_size, 5)\n",
        "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, n_actions)\n",
        "        self.gs = transforms.Grayscale()\n",
        "        self.rs = transforms.Resize(img_size)\n",
        "        self.device = device\n",
        "\n",
        "    def preproc_state(self, state):\n",
        "        # State Preprocessing\n",
        "        state = state[:83,:].transpose(2,0,1) #Torch wants images in format (channels, height, width)\n",
        "        state = torch.from_numpy(state)\n",
        "        state = self.gs(state) # grayscale\n",
        "        state = self.rs(state) # resize\n",
        "        return state/255 # normalize\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutions\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "\n",
        "        # Global Max Pooling\n",
        "        batch_size = x.shape[0]\n",
        "        x = x.reshape(batch_size, self.hidden_size, -1).max(axis=2).values\n",
        "\n",
        "        # Layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "    def act(self, states, exploration=True):\n",
        "        # Stack 4 states\n",
        "        state = torch.vstack([self.preproc_state(state) for state in states]).unsqueeze(0).to(self.device)\n",
        "\n",
        "        # Get Action Probabilities\n",
        "        probs = self.forward(state).cpu()\n",
        "\n",
        "        # Return Action and LogProb\n",
        "        action = probs.argmax(-1)\n",
        "        log_prob = None\n",
        "        if exploration:\n",
        "            m = Categorical(probs)\n",
        "            action = m.sample()\n",
        "            log_prob = m.log_prob(action)\n",
        "        return action.item(), log_prob\n",
        "\n",
        "    def to(self, device):\n",
        "        ret = super().to(device)\n",
        "        ret.device = device\n",
        "        return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5kAeq1Rl1Hyj"
      },
      "outputs": [],
      "source": [
        "MAX_PATIENCE = 100 # Maximum consecutive steps with negative reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sYk1se-R3vmh"
      },
      "outputs": [],
      "source": [
        "def evaluate_agent(env, n_eval_episodes, policy):\n",
        "    episode_rewards = []\n",
        "\n",
        "    for episode in range(n_eval_episodes):\n",
        "        state = env.reset() # state reset\n",
        "\n",
        "        # perform noop for 60 steps (noisy start)\n",
        "        for i in range(60):\n",
        "            state,_,_,_,_ = env.step(0)\n",
        "\n",
        "\n",
        "        done = False\n",
        "\n",
        "        # stats\n",
        "        total_rewards_ep = 0\n",
        "        negative_reward_patience = MAX_PATIENCE\n",
        "\n",
        "        # state\n",
        "        states = deque(maxlen=4)\n",
        "        for i in range(n_frames):\n",
        "            states.append(state)\n",
        "\n",
        "        while not done:\n",
        "            # perform action\n",
        "            action, _ = policy.act(states, exploration=False)\n",
        "\n",
        "            # As in practical 4, we do not consider \"truncated\" (i.e., reaching the max number of steps)\n",
        "            # as a termination condition\n",
        "            state, reward, done, _, _ = env.step(action)\n",
        "            states.append(state)\n",
        "\n",
        "            # handle patience\n",
        "            if reward >=0:\n",
        "                negative_reward_patience = MAX_PATIENCE\n",
        "            else:\n",
        "                negative_reward_patience -= 1\n",
        "                if negative_reward_patience == 0:\n",
        "                    done = True\n",
        "            if done: reward = -100\n",
        "\n",
        "            # stats\n",
        "            total_rewards_ep += reward\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # stats\n",
        "        episode_rewards.append(total_rewards_ep)\n",
        "\n",
        "    # stats\n",
        "    mean_reward = np.mean(episode_rewards)\n",
        "    std_reward = np.std(episode_rewards)\n",
        "\n",
        "    return mean_reward, std_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Uzb4bInRxMsx"
      },
      "outputs": [],
      "source": [
        "def reinforce(policy, optimizer, n_training_episodes=50, gamma=0.99, print_every=10):\n",
        "    # stats\n",
        "    scores_deque = deque(maxlen=100)\n",
        "\n",
        "    for i_episode in range(1, n_training_episodes+1):\n",
        "        saved_log_probs = [] # stores log probs during episode\n",
        "        rewards = [] # stores rewards during episode\n",
        "\n",
        "        # init episode\n",
        "        state = env.reset()\n",
        "        for i in range(60):\n",
        "            state,_,_,_,_ = env.step(0)\n",
        "        done = False\n",
        "\n",
        "        negative_reward_patience = MAX_PATIENCE\n",
        "        states = deque(maxlen=4)\n",
        "        for i in range(n_frames):\n",
        "            states.append(state)\n",
        "\n",
        "\n",
        "        while not done:\n",
        "            action, log_prob = policy.act(states)\n",
        "\n",
        "            saved_log_probs.append(log_prob)\n",
        "\n",
        "            # As in practical 4, we do not consider \"truncated\" (i.e., reaching the max number of steps)\n",
        "            # as a termination condition\n",
        "            state, reward, done, _, _ = env.step(action)\n",
        "\n",
        "            states.append(state)\n",
        "\n",
        "            if reward >=0:\n",
        "                negative_reward_patience = MAX_PATIENCE\n",
        "            else:\n",
        "                negative_reward_patience -= 1\n",
        "                if negative_reward_patience == 0:\n",
        "                    done = True\n",
        "            if done: reward = -100\n",
        "\n",
        "            rewards.append(reward)\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "        scores_deque.append(sum(rewards))\n",
        "\n",
        "\n",
        "        rewards = np.array(rewards)\n",
        "        discounts = np.power(gamma, np.arange(len(rewards)))\n",
        "\n",
        "        policy_loss = 0\n",
        "        for t in range(len(rewards)):\n",
        "            G = (discounts[:len(rewards)-t]*rewards[t:]).sum()\n",
        "            policy_loss += -(gamma**t)*G*saved_log_probs[t]\n",
        "        optimizer.zero_grad()\n",
        "        policy_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i_episode % print_every == 0:\n",
        "            print(f'''Episode {i_episode}\n",
        "                    \\tAverage Score: {np.mean(scores_deque)}\n",
        "                    \\tLast Score: {rewards.sum()}\n",
        "                    \\tEval Score: {evaluate_agent(eval_env,5,policy)}''')\n",
        "            torch.save(policy, 'model.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "GwVv1ETxN7c6"
      },
      "outputs": [],
      "source": [
        "policy = Policy(n_frames, n_actions, 32).to(device)\n",
        "policy = policy.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bQYqOdbiy0ez"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(policy.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "esS1pRU6D9CS",
        "outputId": "022bf43b-7292-4757-9183-6cf61226f22e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Michele\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 10\n",
            "                    \tAverage Score: -120.45986470365558\n",
            "                    \tLast Score: -125.75862068965527\n",
            "                    \tEval Score: (-109.89999999999998, 0.0)\n",
            "Episode 20\n",
            "                    \tAverage Score: -124.14122556530836\n",
            "                    \tLast Score: -118.48403041825088\n",
            "                    \tEval Score: (-109.89999999999998, 0.0)\n",
            "Episode 30\n",
            "                    \tAverage Score: -124.1582052119393\n",
            "                    \tLast Score: -114.89099099099094\n",
            "                    \tEval Score: (-109.89999999999998, 0.0)\n",
            "Episode 40\n",
            "                    \tAverage Score: -129.07855424136937\n",
            "                    \tLast Score: -138.95055762081853\n",
            "                    \tEval Score: (-109.89999999999998, 0.0)\n",
            "Episode 50\n",
            "                    \tAverage Score: -132.1413512250686\n",
            "                    \tLast Score: -120.75135135135133\n",
            "                    \tEval Score: (-109.89999999999998, 0.0)\n"
          ]
        }
      ],
      "source": [
        "reinforce(policy, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85P7ChOqN7c8",
        "outputId": "507d3997-1d9a-44cd-a59d-755b5373487d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "policy.device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTqv8LscQrgn"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLb0dedAQtx4",
        "outputId": "cfbb48a5-c355-4cc0-dceb-90812bfc65e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Policy(\n",
              "  (conv1): Conv2d(4, 32, kernel_size=(7, 7), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=5, bias=True)\n",
              "  (gs): Grayscale(num_output_channels=1)\n",
              "  (rs): Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=warn)\n",
              ")"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "policy = torch.load('model.pt', map_location=device)\n",
        "policy = policy.to(device)\n",
        "policy.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import animation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def save_frames_as_gif(frames, path='./', filename='REINFORCE.gif'):\n",
        "\n",
        "    #Mess with this to change frame size\n",
        "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
        "\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
        "    anim.save(path + filename, writer='imagemagick', fps=60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cq28HU1UTEBo"
      },
      "outputs": [],
      "source": [
        "def play_agent(env, policy):\n",
        "    total_reward = 0\n",
        "    state = env.reset()\n",
        "    frames_gif=[]\n",
        "    for i in range(60):\n",
        "        state,_,_,_,_ = env.step(0)\n",
        "    step = 0\n",
        "    done = False\n",
        "    negative_reward_patience = MAX_PATIENCE\n",
        "    states = deque(maxlen=4)\n",
        "    for i in range(policy.n_frames):\n",
        "        states.append(state)\n",
        "    while not done:\n",
        "        \n",
        "        action, _ = policy.act(states, exploration=False)\n",
        "        new_state, reward, done, _, _ = env.step(action)\n",
        "        states.append(new_state)\n",
        "        if reward >=0:\n",
        "            negative_reward_patience = MAX_PATIENCE\n",
        "        else:\n",
        "            negative_reward_patience -= 1\n",
        "            if negative_reward_patience == 0:\n",
        "                done = True\n",
        "        if done:\n",
        "            reward = -100\n",
        "        total_reward += reward\n",
        "        frames_gif.append(env.render())\n",
        "        if done:\n",
        "            break\n",
        "        state = new_state\n",
        "    save_frames_as_gif(frames_gif)\n",
        "    print(\"Total Reward:\", total_reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRWzLGZVTMiV",
        "outputId": "823268d1-5b75-413b-aab3-8341e8239700"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MovieWriter imagemagick unavailable; using Pillow instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Reward: -109.89999999999998\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "play_agent(eval_env, policy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
